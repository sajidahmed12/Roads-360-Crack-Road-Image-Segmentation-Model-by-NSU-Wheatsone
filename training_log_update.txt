//#(tensorflow) E:\Repository\kittiseg_model_train_ours>python train_model.py
2019-08-18 01:26:24.467290: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-08-18 01:26:24.632689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.64GiB
2019-08-18 01:26:24.636794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-18 01:26:25.125087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-18 01:26:25.126870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-18 01:26:25.128133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-18 01:26:25.129508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6389 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From train_model.py:37: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
2019-08-18 01:26:27.154097: W tensorflow/core/graph/graph_constructor.cc:1272] Importing a graph with a lower producer version 21 into an existing graph with producer version 27. Shape inference will have run different parts of the graph with different producer versions.
WARNING:tensorflow:From C:\Users\Administrator\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
WARNING:tensorflow:From train_model.py:56: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv2d instead.
WARNING:tensorflow:From C:\Users\Administrator\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From train_model.py:60: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv2d_transpose instead.
WARNING:tensorflow:From train_model.py:85: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

Model build successful, starting training
2019-08-18 01:26:58.275954: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:26:58.531217: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:26:59.282372: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.26GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:26:59.858851: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:00.142825: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:01.496237: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.26GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:01.651315: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.26GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:02.604631: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:03.168819: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-08-18 01:27:03.424417: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
EPOCH 1 ...
Loss = 248.623

EPOCH 2 ...
Loss = 5.945

EPOCH 3 ...
Loss = 4.377

EPOCH 4 ...
Loss = 4.126

EPOCH 5 ...
Loss = 3.859

EPOCH 6 ...
Loss = 3.801

EPOCH 7 ...
Loss = 3.736

EPOCH 8 ...
Loss = 3.729

EPOCH 9 ...
Loss = 3.676

EPOCH 10 ...
Loss = 3.643

EPOCH 11 ...
Loss = 3.634

EPOCH 12 ...
Loss = 3.593

EPOCH 13 ...
Loss = 3.571

EPOCH 14 ...
Loss = 3.515

EPOCH 15 ...
Loss = 3.498

EPOCH 16 ...
Loss = 3.534

EPOCH 17 ...
Loss = 3.469

EPOCH 18 ...
Loss = 3.450

EPOCH 19 ...
Loss = 3.390

EPOCH 20 ...
Loss = 3.345

EPOCH 21 ...
Loss = 2.748

EPOCH 22 ...
Loss = 2.607

EPOCH 23 ...
Loss = 2.217

EPOCH 24 ...
Loss = 1.968

EPOCH 25 ...
Loss = 1.870

EPOCH 26 ...
Loss = 1.823

EPOCH 27 ...
Loss = 1.742

EPOCH 28 ...
Loss = 1.650

EPOCH 29 ...
Loss = 1.651

EPOCH 30 ...
Loss = 1.599

EPOCH 31 ...
Loss = 1.494

EPOCH 32 ...
Loss = 1.502

EPOCH 33 ...
Loss = 1.538

EPOCH 34 ...
Loss = 1.433

EPOCH 35 ...
Loss = 1.357

EPOCH 36 ...
Loss = 1.322

EPOCH 37 ...
Loss = 1.290

EPOCH 38 ...
Loss = 1.230

EPOCH 39 ...
Loss = 1.230

EPOCH 40 ...
Loss = 1.185

EPOCH 41 ...
Loss = 1.184

EPOCH 42 ...
Loss = 1.128

EPOCH 43 ...
Loss = 1.109

EPOCH 44 ...
Loss = 1.077

EPOCH 45 ...
Loss = 1.028

EPOCH 46 ...
Loss = 1.033

EPOCH 47 ...
Loss = 0.984

EPOCH 48 ...
Loss = 1.012

EPOCH 49 ...
Loss = 0.984

EPOCH 50 ...
Loss = 0.911

EPOCH 51 ...
Loss = 0.890

EPOCH 52 ...
Loss = 0.866

EPOCH 53 ...
Loss = 0.849

EPOCH 54 ...
Loss = 0.843

EPOCH 55 ...
Loss = 0.827

EPOCH 56 ...
Loss = 0.819

EPOCH 57 ...
Loss = 0.866

EPOCH 58 ...
Loss = 0.834

EPOCH 59 ...
Loss = 0.795

EPOCH 60 ...
Loss = 0.811

EPOCH 61 ...
Loss = 0.797

EPOCH 62 ...
Loss = 0.764

EPOCH 63 ...
Loss = 0.745

EPOCH 64 ...
Loss = 0.731

EPOCH 65 ...
Loss = 0.712

EPOCH 66 ...
Loss = 0.694

EPOCH 67 ...
Loss = 0.702

EPOCH 68 ...
Loss = 0.692

EPOCH 69 ...
Loss = 0.681

EPOCH 70 ...
Loss = 0.653

EPOCH 71 ...
Loss = 0.639

EPOCH 72 ...
Loss = 0.640

EPOCH 73 ...
Loss = 0.636

EPOCH 74 ...
Loss = 0.630

EPOCH 75 ...
Loss = 0.624

EPOCH 76 ...
Loss = 0.645

EPOCH 77 ...
Loss = 0.635

EPOCH 78 ...
Loss = 0.620

EPOCH 79 ...
Loss = 0.616

EPOCH 80 ...
Loss = 0.604

EPOCH 81 ...
Loss = 0.604

EPOCH 82 ...
Loss = 0.571

EPOCH 83 ...
Loss = 0.564

EPOCH 84 ...
Loss = 0.570

EPOCH 85 ...
Loss = 0.571

EPOCH 86 ...
Loss = 0.571

EPOCH 87 ...
Loss = 0.564

EPOCH 88 ...
Loss = 0.552

EPOCH 89 ...
Loss = 0.560

EPOCH 90 ...
Loss = 0.574

EPOCH 91 ...
Loss = 0.549

EPOCH 92 ...
Loss = 0.542

EPOCH 93 ...
Loss = 0.532

EPOCH 94 ...
Loss = 0.529

EPOCH 95 ...
Loss = 0.522

EPOCH 96 ...
Loss = 0.520

EPOCH 97 ...
Loss = 0.515

EPOCH 98 ...
Loss = 0.514

EPOCH 99 ...
Loss = 0.514

EPOCH 100 ...
Loss = 0.510

EPOCH 101 ...
Loss = 0.502

EPOCH 102 ...
Loss = 0.490

EPOCH 103 ...
Loss = 0.486

EPOCH 104 ...
Loss = 0.487

EPOCH 105 ...
Loss = 0.490

EPOCH 106 ...
Loss = 0.495

EPOCH 107 ...
Loss = 0.491

EPOCH 108 ...
Loss = 0.482

EPOCH 109 ...
Loss = 0.484

EPOCH 110 ...
Loss = 0.465

EPOCH 111 ...
Loss = 0.457

EPOCH 112 ...
Loss = 0.456

EPOCH 113 ...
Loss = 0.450

EPOCH 114 ...
Loss = 0.456

EPOCH 115 ...
Loss = 0.451

EPOCH 116 ...
Loss = 0.452

EPOCH 117 ...
Loss = 0.443

EPOCH 118 ...
Loss = 0.442

EPOCH 119 ...
Loss = 0.435

EPOCH 120 ...
Loss = 0.436

EPOCH 121 ...
Loss = 0.438

EPOCH 122 ...
Loss = 0.431

EPOCH 123 ...
Loss = 0.426

EPOCH 124 ...
Loss = 0.427

EPOCH 125 ...
Loss = 0.427

EPOCH 126 ...
Loss = 0.423

EPOCH 127 ...
Loss = 0.414

EPOCH 128 ...
Loss = 0.412

EPOCH 129 ...
Loss = 0.416

EPOCH 130 ...
Loss = 0.425

EPOCH 131 ...
Loss = 0.426

EPOCH 132 ...
Loss = 0.421

EPOCH 133 ...
Loss = 0.414

EPOCH 134 ...
Loss = 0.405

EPOCH 135 ...
Loss = 0.404

EPOCH 136 ...
Loss = 0.404

EPOCH 137 ...
Loss = 0.416

EPOCH 138 ...
Loss = 0.404

EPOCH 139 ...
Loss = 0.405

EPOCH 140 ...
Loss = 0.401

EPOCH 141 ...
Loss = 0.392

EPOCH 142 ...
Loss = 0.392

EPOCH 143 ...
Loss = 0.385

EPOCH 144 ...
Loss = 0.388

EPOCH 145 ...
Loss = 0.389

EPOCH 146 ...
Loss = 0.379

EPOCH 147 ...
Loss = 0.376

EPOCH 148 ...
Loss = 0.376

EPOCH 149 ...
Loss = 0.378

EPOCH 150 ...
Loss = 0.377

EPOCH 151 ...
Loss = 0.372

EPOCH 152 ...
Loss = 0.368

EPOCH 153 ...
Loss = 0.371

EPOCH 154 ...
Loss = 0.366

EPOCH 155 ...
Loss = 0.367

EPOCH 156 ...
Loss = 0.369

EPOCH 157 ...
Loss = 0.361

EPOCH 158 ...
Loss = 0.365

EPOCH 159 ...
Loss = 0.362

EPOCH 160 ...
Loss = 0.360

EPOCH 161 ...
Loss = 0.357

EPOCH 162 ...
Loss = 0.380

EPOCH 163 ...
Loss = 0.379

EPOCH 164 ...
Loss = 0.380

EPOCH 165 ...
Loss = 0.371

EPOCH 166 ...
Loss = 0.361

EPOCH 167 ...
Loss = 0.351

EPOCH 168 ...
Loss = 0.347

EPOCH 169 ...
Loss = 0.351

EPOCH 170 ...
Loss = 0.350

EPOCH 171 ...
Loss = 0.343

EPOCH 172 ...
Loss = 0.344

EPOCH 173 ...
Loss = 0.345

EPOCH 174 ...
Loss = 0.350

EPOCH 175 ...
Loss = 0.350

EPOCH 176 ...
Loss = 0.347

EPOCH 177 ...
Loss = 0.346

EPOCH 178 ...
Loss = 0.351

EPOCH 179 ...
Loss = 0.343

EPOCH 180 ...
Loss = 0.336

EPOCH 181 ...
Loss = 0.335

EPOCH 182 ...
Loss = 0.335

EPOCH 183 ...
Loss = 0.340

EPOCH 184 ...
Loss = 0.340

EPOCH 185 ...
Loss = 0.339

EPOCH 186 ...
Loss = 0.337

EPOCH 187 ...
Loss = 0.334

EPOCH 188 ...
Loss = 0.335

EPOCH 189 ...
Loss = 0.330

EPOCH 190 ...
Loss = 0.327

EPOCH 191 ...
Loss = 0.323

EPOCH 192 ...
Loss = 0.323

EPOCH 193 ...
Loss = 0.325

EPOCH 194 ...
Loss = 0.321

EPOCH 195 ...
Loss = 0.325

EPOCH 196 ...
Loss = 0.500

EPOCH 197 ...
Loss = 0.709

EPOCH 198 ...
Loss = 0.595

EPOCH 199 ...
Loss = 0.492

EPOCH 200 ...
Loss = 0.467

EPOCH 201 ...
Loss = 0.438

EPOCH 202 ...
Loss = 0.404

EPOCH 203 ...
Loss = 0.385

EPOCH 204 ...
Loss = 0.363

EPOCH 205 ...
Loss = 0.362

EPOCH 206 ...
Loss = 0.347

EPOCH 207 ...
Loss = 0.338

EPOCH 208 ...
Loss = 0.330

EPOCH 209 ...
Loss = 0.332

EPOCH 210 ...
Loss = 0.326

EPOCH 211 ...
Loss = 0.325

EPOCH 212 ...
Loss = 0.323

EPOCH 213 ...
Loss = 0.321

EPOCH 214 ...
Loss = 0.321

EPOCH 215 ...
Loss = 0.321

EPOCH 216 ...
Loss = 0.320

EPOCH 217 ...
Loss = 0.316

EPOCH 218 ...
Loss = 0.314

EPOCH 219 ...
Loss = 0.313

EPOCH 220 ...
Loss = 0.314

EPOCH 221 ...
Loss = 0.315

EPOCH 222 ...
Loss = 0.311

EPOCH 223 ...
Loss = 0.312

EPOCH 224 ...
Loss = 0.307

EPOCH 225 ...
Loss = 0.308

EPOCH 226 ...
Loss = 0.305

EPOCH 227 ...
Loss = 0.301

EPOCH 228 ...
Loss = 0.304

EPOCH 229 ...
Loss = 0.303

EPOCH 230 ...
Loss = 0.303

EPOCH 231 ...
Loss = 0.300

EPOCH 232 ...
Loss = 0.300

EPOCH 233 ...
Loss = 0.297

EPOCH 234 ...
Loss = 0.297

EPOCH 235 ...
Loss = 0.301

EPOCH 236 ...
Loss = 0.299

EPOCH 237 ...
Loss = 0.298

EPOCH 238 ...
Loss = 0.296

EPOCH 239 ...
Loss = 0.299

EPOCH 240 ...
Loss = 0.301

EPOCH 241 ...
Loss = 0.298

EPOCH 242 ...
Loss = 0.299

EPOCH 243 ...
Loss = 0.298

EPOCH 244 ...
Loss = 0.295

EPOCH 245 ...
Loss = 0.293

EPOCH 246 ...
Loss = 0.293

EPOCH 247 ...
Loss = 0.295

EPOCH 248 ...
Loss = 0.294

EPOCH 249 ...
Loss = 0.290

EPOCH 250 ...
Loss = 0.291

EPOCH 251 ...
Loss = 0.288

EPOCH 252 ...
Loss = 0.285

EPOCH 253 ...
Loss = 0.286

EPOCH 254 ...
Loss = 0.286

EPOCH 255 ...
Loss = 0.285

EPOCH 256 ...
Loss = 0.282

EPOCH 257 ...
Loss = 0.284

EPOCH 258 ...
Loss = 0.285

EPOCH 259 ...
Loss = 0.291

EPOCH 260 ...
Loss = 0.285

EPOCH 261 ...
Loss = 0.285

EPOCH 262 ...
Loss = 0.283

EPOCH 263 ...
Loss = 0.286

EPOCH 264 ...
Loss = 0.281

EPOCH 265 ...
Loss = 0.281

EPOCH 266 ...
Loss = 0.280

EPOCH 267 ...
Loss = 0.284

EPOCH 268 ...
Loss = 0.281

EPOCH 269 ...
Loss = 0.277

EPOCH 270 ...
Loss = 0.275

EPOCH 271 ...
Loss = 0.275

EPOCH 272 ...
Loss = 0.278

EPOCH 273 ...
Loss = 0.276

EPOCH 274 ...
Loss = 0.277

EPOCH 275 ...
Loss = 0.278

EPOCH 276 ...
Loss = 0.277

EPOCH 277 ...
Loss = 0.279

EPOCH 278 ...
Loss = 0.279

EPOCH 279 ...
Loss = 0.275

EPOCH 280 ...
Loss = 0.289

EPOCH 281 ...
Loss = 0.342

EPOCH 282 ...
Loss = 0.454

EPOCH 283 ...
Loss = 0.542

EPOCH 284 ...
Loss = 0.813

EPOCH 285 ...
Loss = 0.779

EPOCH 286 ...
Loss = 0.543

EPOCH 287 ...
Loss = 0.440

EPOCH 288 ...
Loss = 0.378

EPOCH 289 ...
Loss = 0.351

EPOCH 290 ...
Loss = 0.337

EPOCH 291 ...
Loss = 0.321

EPOCH 292 ...
Loss = 0.311

EPOCH 293 ...
Loss = 0.303

EPOCH 294 ...
Loss = 0.297

EPOCH 295 ...
Loss = 0.292

EPOCH 296 ...
Loss = 0.290

EPOCH 297 ...
Loss = 0.291

EPOCH 298 ...
Loss = 0.285

EPOCH 299 ...
Loss = 0.282

EPOCH 300 ...
Loss = 0.281

EPOCH 301 ...
Loss = 0.283

EPOCH 302 ...
Loss = 0.280

EPOCH 303 ...
Loss = 0.280

EPOCH 304 ...
Loss = 0.277

EPOCH 305 ...
Loss = 0.276

EPOCH 306 ...
Loss = 0.274

EPOCH 307 ...
Loss = 0.272

EPOCH 308 ...
Loss = 0.271

EPOCH 309 ...
Loss = 0.273

EPOCH 310 ...
Loss = 0.274

EPOCH 311 ...
Loss = 0.273

EPOCH 312 ...
Loss = 0.270

EPOCH 313 ...
Loss = 0.271

EPOCH 314 ...
Loss = 0.269

EPOCH 315 ...
Loss = 0.266

EPOCH 316 ...
Loss = 0.268

EPOCH 317 ...
Loss = 0.267

EPOCH 318 ...
Loss = 0.272

EPOCH 319 ...
Loss = 0.271

EPOCH 320 ...
Loss = 0.280

EPOCH 321 ...
Loss = 0.269

EPOCH 322 ...
Loss = 0.263

EPOCH 323 ...
Loss = 0.264

EPOCH 324 ...
Loss = 0.262

EPOCH 325 ...
Loss = 0.260

EPOCH 326 ...
Loss = 0.266

EPOCH 327 ...
Loss = 0.260

EPOCH 328 ...
Loss = 0.258

EPOCH 329 ...
Loss = 0.258

EPOCH 330 ...
Loss = 0.258

EPOCH 331 ...
Loss = 0.262

EPOCH 332 ...
Loss = 0.260

EPOCH 333 ...
Loss = 0.256

EPOCH 334 ...
Loss = 0.254

EPOCH 335 ...
Loss = 0.257

EPOCH 336 ...
Loss = 0.255

EPOCH 337 ...
Loss = 0.256

EPOCH 338 ...
Loss = 0.254

EPOCH 339 ...
Loss = 0.251

EPOCH 340 ...
Loss = 0.253

EPOCH 341 ...
Loss = 0.259

EPOCH 342 ...
Loss = 0.261

EPOCH 343 ...
Loss = 0.261

EPOCH 344 ...
Loss = 0.254

EPOCH 345 ...
Loss = 0.252

EPOCH 346 ...
Loss = 0.250

EPOCH 347 ...
Loss = 0.257

EPOCH 348 ...
Loss = 0.255

EPOCH 349 ...
Loss = 0.255

EPOCH 350 ...
Loss = 0.257

EPOCH 351 ...
Loss = 0.250

EPOCH 352 ...
Loss = 0.253

EPOCH 353 ...
Loss = 0.250

EPOCH 354 ...
Loss = 0.247

EPOCH 355 ...
Loss = 0.247

EPOCH 356 ...
Loss = 0.251

EPOCH 357 ...
Loss = 0.251

EPOCH 358 ...
Loss = 0.248

EPOCH 359 ...
Loss = 0.248

EPOCH 360 ...
Loss = 0.250

EPOCH 361 ...
Loss = 0.252

EPOCH 362 ...
Loss = 0.250

EPOCH 363 ...
Loss = 0.251

EPOCH 364 ...
Loss = 0.251

EPOCH 365 ...
Loss = 0.254

EPOCH 366 ...
Loss = 0.266

EPOCH 367 ...
Loss = 0.272

EPOCH 368 ...
Loss = 0.260

EPOCH 369 ...
Loss = 0.254

EPOCH 370 ...
Loss = 0.251

EPOCH 371 ...
Loss = 0.253

EPOCH 372 ...
Loss = 0.256

EPOCH 373 ...
Loss = 0.254

EPOCH 374 ...
Loss = 0.250

EPOCH 375 ...
Loss = 0.252

EPOCH 376 ...
Loss = 0.247

EPOCH 377 ...
Loss = 0.244

EPOCH 378 ...
Loss = 0.243

EPOCH 379 ...
Loss = 0.243

EPOCH 380 ...
Loss = 0.245

EPOCH 381 ...
Loss = 0.248

EPOCH 382 ...
Loss = 0.250

EPOCH 383 ...
Loss = 0.248

EPOCH 384 ...
Loss = 0.243

EPOCH 385 ...
Loss = 0.248

EPOCH 386 ...
Loss = 0.256

EPOCH 387 ...
Loss = 0.246

EPOCH 388 ...
Loss = 0.243

EPOCH 389 ...
Loss = 0.240

EPOCH 390 ...
Loss = 0.246

EPOCH 391 ...
Loss = 0.247

EPOCH 392 ...
Loss = 0.249

EPOCH 393 ...
Loss = 0.247

EPOCH 394 ...
Loss = 0.246

EPOCH 395 ...
Loss = 0.243

EPOCH 396 ...
Loss = 0.243

EPOCH 397 ...
Loss = 0.246

EPOCH 398 ...
Loss = 0.242

EPOCH 399 ...
Loss = 0.242

EPOCH 400 ...
Loss = 0.241

EPOCH 401 ...
Loss = 0.236

EPOCH 402 ...
Loss = 0.237

EPOCH 403 ...
Loss = 0.237

EPOCH 404 ...
Loss = 0.240

EPOCH 405 ...
Loss = 0.240

EPOCH 406 ...
Loss = 0.243

EPOCH 407 ...
Loss = 0.240

EPOCH 408 ...
Loss = 0.239

EPOCH 409 ...
Loss = 0.241

EPOCH 410 ...
Loss = 0.237

EPOCH 411 ...
Loss = 0.241

EPOCH 412 ...
Loss = 0.236

EPOCH 413 ...
Loss = 0.244

EPOCH 414 ...
Loss = 0.250

EPOCH 415 ...
Loss = 0.268

EPOCH 416 ...
Loss = 0.250

EPOCH 417 ...
Loss = 0.246

EPOCH 418 ...
Loss = 0.240

EPOCH 419 ...
Loss = 0.237

EPOCH 420 ...
Loss = 0.237

EPOCH 421 ...
Loss = 0.241

EPOCH 422 ...
Loss = 0.241

EPOCH 423 ...
Loss = 0.241

EPOCH 424 ...
Loss = 0.236

EPOCH 425 ...
Loss = 0.237

EPOCH 426 ...
Loss = 0.237

EPOCH 427 ...
Loss = 0.235

EPOCH 428 ...
Loss = 0.233

EPOCH 429 ...
Loss = 0.231

EPOCH 430 ...
Loss = 0.232

EPOCH 431 ...
Loss = 0.232

EPOCH 432 ...
Loss = 0.234

EPOCH 433 ...
Loss = 0.229

EPOCH 434 ...
Loss = 0.229

EPOCH 435 ...
Loss = 0.230

EPOCH 436 ...
Loss = 0.230

EPOCH 437 ...
Loss = 0.229

EPOCH 438 ...
Loss = 0.230

EPOCH 439 ...
Loss = 0.231

EPOCH 440 ...
Loss = 0.227

EPOCH 441 ...
Loss = 0.228

EPOCH 442 ...
Loss = 0.230

EPOCH 443 ...
Loss = 0.231

EPOCH 444 ...
Loss = 0.238

EPOCH 445 ...
Loss = 1.471

EPOCH 446 ...
Loss = 3.401

EPOCH 447 ...
Loss = 2.124

EPOCH 448 ...
Loss = 1.736

EPOCH 449 ...
Loss = 1.580

EPOCH 450 ...
Loss = 1.435

EPOCH 451 ...
Loss = 1.295

EPOCH 452 ...
Loss = 1.194

EPOCH 453 ...
Loss = 1.128

EPOCH 454 ...
Loss = 1.064

EPOCH 455 ...
Loss = 1.018

EPOCH 456 ...
Loss = 0.968

EPOCH 457 ...
Loss = 0.901

EPOCH 458 ...
Loss = 0.869

EPOCH 459 ...
Loss = 0.835

EPOCH 460 ...
Loss = 0.802

EPOCH 461 ...
Loss = 0.751

EPOCH 462 ...
Loss = 0.740

EPOCH 463 ...
Loss = 0.691

EPOCH 464 ...
Loss = 0.657

EPOCH 465 ...
Loss = 0.623

EPOCH 466 ...
Loss = 0.602

EPOCH 467 ...
Loss = 0.583

EPOCH 468 ...
Loss = 0.605

EPOCH 469 ...
Loss = 0.565

EPOCH 470 ...
Loss = 0.520

EPOCH 471 ...
Loss = 0.507

EPOCH 472 ...
Loss = 0.504

EPOCH 473 ...
Loss = 0.486

EPOCH 474 ...
Loss = 0.476

EPOCH 475 ...
Loss = 0.469

EPOCH 476 ...
Loss = 0.456

EPOCH 477 ...
Loss = 0.443

EPOCH 478 ...
Loss = 0.437

EPOCH 479 ...
Loss = 0.421

EPOCH 480 ...
Loss = 0.417

EPOCH 481 ...
Loss = 0.405

EPOCH 482 ...
Loss = 0.402

EPOCH 483 ...
Loss = 0.398

EPOCH 484 ...
Loss = 0.385

EPOCH 485 ...
Loss = 0.388

EPOCH 486 ...
Loss = 0.380

EPOCH 487 ...
Loss = 0.374

EPOCH 488 ...
Loss = 0.362

EPOCH 489 ...
Loss = 0.368

EPOCH 490 ...
Loss = 0.359

EPOCH 491 ...
Loss = 0.354

EPOCH 492 ...
Loss = 0.348

EPOCH 493 ...
Loss = 0.343

EPOCH 494 ...
Loss = 0.342

EPOCH 495 ...
Loss = 0.338

EPOCH 496 ...
Loss = 0.337

EPOCH 497 ...
Loss = 0.334

EPOCH 498 ...
Loss = 0.335

EPOCH 499 ...
Loss = 0.330

EPOCH 500 ...
Loss = 0.339

Training Finished. Saving test images to: ./runs\1566087926.6596122
All done!